\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry,amsmath,color,graphicx,latexsym,amsfonts}
%\usepackage{authblk}
\geometry{margin=1in}

% %opening
\title{Finding Parallelism in the Edge-Weighted Page Rank Problem}
\author{Sam Estes, Tim Smith, Siddhant Wahal, Gopal Yalla}
\date{May 10, 2017}
%\institute{CSE 392: Parallel Algorithms \\ Final Report}

%% --- New commands
\newcommand{\pderiv}[3][]{% \pderiv[<order>]{<func>}{<var>} 
  \ensuremath{\frac{\partial^{#1} {#2}}{\partial {#3}^{#1}}}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\newcommand{\degSym}{$^{\circ}$}
\newcommand{\noi}{\noindent}
\newcommand{\bigo}[1]{\mathcal{O}\left( #1 \right)}

%\renewcommand\Authfont{\small}
%\renewcommand\Affilfont{\itshape\footnotesize}
\begin{document}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 1. Introduction
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

We consider the problem of ranking webpages on the internet based on a user's
query. We view the internet as a graph where the webpages are nodes and the
links are edges. 
In the PageRank problem a random walker moves across a graph, transitioning to
adjacent nodes along an edge or jumping to a new, non-adjacent node. The
distribution of positions for a walker at time $t$ is given by the discrete-time
Markov process: 

\begin{equation}
        x^{(t+1)}=\alpha P x^{(t)} + (1-\alpha) v \; ,
\label{eq:pagerank_markov}
\end{equation}

\noi where $P$ is the edge transition probability matrix and $v$ represents jump or
teleport probabilities. Here $\alpha$ is the edge
transition probability (i.e. how likely the walker is to transition to an
adjacent node), and $(1-\alpha)$ represents the teleport probability (e.g. the
probability a user goes to a webpage in their bookmarks rather clicking a link).
Defining $w$ as a vector of personalization parameters specified by the user's
query, we seek to solve the
edge-weighted personalized PageRank problem: 

\begin{equation}
        Mx=b
\label{eq:pagerank_linear}
\end{equation}

\noi where $M(w) = (I-\alpha P(w))$ and $b = (1-\alpha)v(w)$, and $w \in
\mathbb{R}^d$ is
the \textit{personalization vector}, which specifies the topic preference for
a given query. 

In general, computing the edge-weighted personalized page rank vector is expensive
and not feasible for online, interactive situations. \cite{xie} present a
solution to this problem, where they solve Eqn. (\ref{eq:pagerank_linear}) for many
sample queries preemptively (i.e. in an ``offline'' computation). They find low
dimensional subspaces for
approximating each of these samples and solve a constrained least squares
problem to estimate the PageRank vector in an ``online'' query. The solution to
these low dimensional systems can be computed almost immediately, such that
a user can query a database at interactive speeds.   

Since the algorithm presented in \cite{xie} was already so fast, it seemed
unnecessary to try to formulate a parallel implementation. Therefore we looked
to improving the more expensive offline computation, which solves Eqn.
(\ref{eq:pagerank_linear}) exactly. Speeding up this computation could allow for
an implementation presented by \cite{xie} where the database is updated
frequently, requiring successive offline computations for producing sample
PageRank vectors.

The sequential complexity for solving Eqn. (\ref{eq:pagerank_linear}) amounts to
solving iteratively applying a MatVec (e.g. for a Jacobi iteration), which is
naively $\mathcal{O}(N^2)$ complexity. In our approach, we first reorder the
matrix $M$ by successively coarsening the related adjacency matrix and
implementing a spectral bisection algorithm to improve data locality. We then
solve Eqn. (\ref{eq:pagerank_linear}) with a Jacobi iterative scheme motivated
by the Markov process given by Eqn. (\ref{eq:pagerank_markov}). Here all
matrices and vectors are stored using Compressed Sparse Column (CSC) format. We
implemented our method using a shared memory approach in C++ using OpenMP on the Knights Landing (KNL) processors on
Stampede. We tested our methods on the DBLP computer science citation database
\cite{dblp} and a network of facebook users \cite{facebook}. 

We found that the computations involved with reordering the matrix $M$ (i.e.
coarsening and spectral bisection) were much more complex than simply solving
the linear system. The key here was rewriting the linear solver to handle the
CSC format, and only perform computations for nonzero entries of the right hand
side, $b$. Thus while the coarsening and reordering strategies are theoretically
very interesting and scaled well up to 32 cores on the KNL nodes, 
we did not find them useful for this particular application. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 2. Methodology
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Our problem takes the view of a network of users in the facebook data or
citations in the DBLP database. Two vertices are connected by an edge when e.g. two
users are friends on facebook or when one paper cites another in the DBLP graph.
These graphs are highly sparse, and randomly ordered.
The algorithm we implemented follows three basic steps: (1) successively coarsen
the graph to reduce the number of effective nodes, (2) reorder the graph via
spectral bisection, and (3) solve the linear system with a Jacobi iterative
method motivated by Eqn. (\ref{eq:pagerank_markov}) in Compressed Sparse
Column (CSC) format. We discuss each of these separate parts in detail here. 

The graph coarsening 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 3. Experimental setup
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experimental Setup}
\subsection{Implementation Details}

In order to test our methodology, we wrote a C++
package called {\rm spiC} (Sparse Pagerank Implementation in C). Given a
graph, our pacakge can solve the page rank problem using a combination of coarsening, spectral
bisection, and a parallel matvec with CSC formatted data inside a Jacobi
iterator. The code was built on the ICES machines, as well as on \textit{Stampede 2} at TACC using the gnu
compilers g++/gcc. Regarding external dependencies, {\rm spiC}, makes use of
{\rm ARPACK}, {\rm SuperLU}, and {\rm Boost}. {\rm ARPACK} is used in conjuction
with {\rm SuperLU} to solve for the two least significant eigenvalues and
eigenvectors of a given
matrix; this is the same package used by the Matlab function ``eigs()''. {\rm
Boost} program options is used for the API. Our package comes with two
makefiles: one for KNL, which requires the use of Intel's MKL package for BLAS
and LAPACK, and one for the ICES desktops and similar machines. Issuing a `make
dep' will build all external dependencies. Moreover, issuing a `make install' will
build the source code and issuing a `make check' command will run the unit test suite.  

\subsection{List of Experiments}

Aside from the unit test suite in the code, which contained small example graphs
for verification purposes, we tested our codes on two main datasets: The DBLP
collaboration network dataset and the Facebook social circles data set
\cite{snapnets}.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 4. Results
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CITATIONS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage

%\addcontentsline{toc}{subsubsection}{\protect\numberline{\thesubsubsection}
%  line added to TOC: subsubsection one}

%\addcontentsline{toc}{section}{References} 

\bibliographystyle{ieeetr} 
\bibliography{spicy}


\end{document}

